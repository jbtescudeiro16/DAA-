{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1 style=\"font-family: 'Times New Roman', Times, serif; font-size: 60px;\">DAA</h1>\n",
    "<h2 style=\"font-family: 'Times New Roman', Times, serif; font-size: 40px;\">Stacking XGBoost</h2>\n",
    "</center>\n",
    "\n",
    "<font face=\"Times New Roman\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: 'Times New Roman'\">Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                                                                                 # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt                                                                     # For data visualization\n",
    "import seaborn as sns                                                                               # For enhanced data visualization\n",
    "from sklearn.model_selection import train_test_split                                                # For splitting data\n",
    "import xgboost as xgb                                                                               # For the XGBoost\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, make_scorer    # For evaluating model performance\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV                # For cross-validation\n",
    "import os                                                                                           # For interacting with the operating system\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: 'Times New Roman'\">Load All Datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"Ficheiros/Ficheiros_Models/Final.csv\", na_filter = False)\n",
    "final_teste = pd.read_csv(\"Ficheiros/Ficheiros_Models/Final_Teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: 'Times New Roman'\">XGBoost</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.drop(columns=['injection'])\n",
    "y = final['injection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "rf_model = RandomForestClassifier(random_state=2024, n_estimators=1000, criterion='entropy', max_depth=25, min_samples_split=15, min_samples_leaf=1, bootstrap=True)\n",
    "gb_model = GradientBoostingClassifier(random_state=2025, n_estimators=200, learning_rate=0.01, max_depth=5, subsample=0.9, min_samples_split=15)\n",
    "et_model = ExtraTreesClassifier(random_state=2026, n_estimators=400, max_depth=50, min_samples_split=7, criterion='entropy', min_samples_leaf=1)\n",
    "xgb_model = XGBClassifier(random_state=2027, learning_rate=0.09, n_estimators=150, max_depth=5, objective='multi:softprob')\n",
    "\n",
    "# Define the stacking classifier with the chosen models as base estimators\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('gb', gb_model), ('et', et_model)],\n",
    "    final_estimator=XGBClassifier(random_state=2028, learning_rate=0.09, n_estimators=150, max_depth=5, objective='multi:softprob'),\n",
    "    cv=KFold(n_splits=10, shuffle=True)\n",
    ")\n",
    "\n",
    "# Train the stacking model on the training data\n",
    "stacking_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "X_test = final_teste\n",
    "y_pred = stacking_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very High'}\n",
    "\n",
    "# Aplica o mapeamento inverso às previsões 'y_pred'\n",
    "y_pred = [reverse_mapping[pred] for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões salvas em Stacking_XGBoost.csv\n"
     ]
    }
   ],
   "source": [
    "# Salvar as previsões em 'prediction_results.csv'\n",
    "with open('Outputs/Stacking_XGBoost.csv', 'w') as file:\n",
    "    file.write(\"RowId,Result\\n\")\n",
    "    for row_id, prediction in enumerate(y_pred, start=1):\n",
    "        file.write(f\"{row_id},{prediction}\\n\")\n",
    "\n",
    "print(\"Previsões salvas em Stacking_XGBoost.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
