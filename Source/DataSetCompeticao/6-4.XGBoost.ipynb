{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1 style=\"font-family: 'Times New Roman', Times, serif; font-size: 60px;\">DAA</h1>\n",
    "<h2 style=\"font-family: 'Times New Roman', Times, serif; font-size: 40px;\">XGBoost</h2>\n",
    "</center>\n",
    "\n",
    "<font face=\"Times New Roman\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: 'Times New Roman'\">Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                                                                                 # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt                                                                     # For data visualization\n",
    "import seaborn as sns                                                                               # For enhanced data visualization\n",
    "from sklearn.model_selection import train_test_split                                                # For splitting data\n",
    "import xgboost as xgb                                                                               # For the XGBoost\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, make_scorer    # For evaluating model performance\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV                # For cross-validation\n",
    "import os                                                                                           # For interacting with the operating system\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: 'Times New Roman'\">Load All Datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"Ficheiros/Ficheiros_Models/Final.csv\", na_filter = False)\n",
    "final_teste = pd.read_csv(\"Ficheiros/Ficheiros_Models/Final_Teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: 'Times New Roman'\">XGBoost</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: 'Times New Roman'\">Test Locally</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.drop(columns=['injection'])\n",
    "y = final['injection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2024)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.085, 0.09, 0.095, 0.1],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 10],\n",
    "    'objective': ['binary:logistic', 'multi:softmax', 'multi:softprob'],\n",
    "}\n",
    "\n",
    "modelo = xgb.XGBClassifier(random_state=2024) # objective='binary:logistic'\n",
    "scoring = make_scorer(accuracy_score)\n",
    "cv_value = 10\n",
    "grid_accuracy = GridSearchCV(estimator=modelo, param_grid=param_grid, scoring=scoring, cv=cv_value, refit=True)\n",
    "\n",
    "grid_accuracy.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_accuracy.best_estimator_\n",
    "best_model_params = best_model.get_params()\n",
    "\n",
    "print(\"Hyperparameters of the Best Model:\")\n",
    "for param, value in best_model_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print the cross-validated accuracy scores\n",
    "cv_scores = grid_accuracy.cv_results_['mean_test_score']\n",
    "# print(\"Cross-validated Accuracy Scores: {}\".format(cv_scores))\n",
    "print(\"Mean Accuracy: {:.2f}%\".format(cv_scores.mean() * 100))\n",
    "\n",
    "accuracy_injection = accuracy_score(y_test, y_pred)\n",
    "print(\"XGBoost Model Accuracy: {:.2f}%\".format(accuracy_injection * 100))\n",
    "\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_report_str)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Define a custom color palette\n",
    "color_palette = sns.light_palette(\"seagreen\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=color_palette, cbar=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Customize tick labels\n",
    "tick_labels = ['None', 'Low', 'Medium', 'High', 'Very High']\n",
    "plt.xticks(ticks=range(len(tick_labels)), labels=tick_labels)\n",
    "plt.yticks(ticks=range(len(tick_labels)), labels=tick_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: 'Times New Roman'\">Kaggle</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kaggle = pd.read_csv(\"Ficheiros/Ficheiros_Models/Final.csv\", na_filter = False)\n",
    "final_teste_kaggle = pd.read_csv(\"Ficheiros/Ficheiros_Models/Final_Teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle = final_kaggle.drop(columns=['injection'])\n",
    "y_kaggle = final_kaggle['injection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\miniconda3\\envs\\daa1\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_teste' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m best_model_kaggle_adaboost \u001b[38;5;241m=\u001b[39m grid_accuracy_kaggle_adaboost\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Make predictions using the best model\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m X_teste_kaggle \u001b[38;5;241m=\u001b[39m final_teste\n\u001b[0;32m     37\u001b[0m y_pred_kaggle_adaboost \u001b[38;5;241m=\u001b[39m best_model_kaggle_adaboost\u001b[38;5;241m.\u001b[39mpredict(X_teste_kaggle)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_teste' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid_kaggle = {\n",
    "    'learning_rate': [0.09],\n",
    "    'n_estimators': [150],\n",
    "    'max_depth': [5],\n",
    "    'objective': ['multi:softprob'],\n",
    "}\n",
    "\n",
    "modelo_kaggle = xgb.XGBClassifier(random_state=2023) # objective='binary:logistic', \n",
    "scoring_kaggle = make_scorer(accuracy_score)\n",
    "cv_value_kaggle = 10\n",
    "grid_accuracy_kaggle = GridSearchCV(estimator=modelo_kaggle, param_grid=param_grid_kaggle, scoring=scoring_kaggle, cv=cv_value_kaggle, refit=True)\n",
    "\n",
    "grid_accuracy_kaggle.fit(X_kaggle, y_kaggle)\n",
    "\n",
    "best_model_kaggle = grid_accuracy_kaggle.best_estimator_\n",
    "X_teste_kaggle = final_teste\n",
    "y_pred_kaggle = best_model_kaggle.predict(X_teste_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = {0: 'None', 1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very High'}\n",
    "\n",
    "# Aplica o mapeamento inverso às previsões 'y_pred'\n",
    "y_pred_kaggle = [reverse_mapping[pred] for pred in y_pred_kaggle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões salvas em XGBoost.csv\n"
     ]
    }
   ],
   "source": [
    "# Salvar as previsões em 'prediction_results.csv'\n",
    "with open('Outputs/XGBoost.csv', 'w') as file:\n",
    "    file.write(\"RowId,Result\\n\")\n",
    "    for row_id, prediction in enumerate(y_pred_kaggle, start=1):\n",
    "        file.write(f\"{row_id},{prediction}\\n\")\n",
    "\n",
    "print(\"Previsões salvas em XGBoost.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meuambiente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
